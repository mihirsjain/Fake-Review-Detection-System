# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fDA9F82NsMGKbFgzzqcb0FLHykzVObzo
"""

#import libraries
import numpy as np
from flask import Flask, request, jsonify, render_template
import pickle
import nltk
import re
from sklearn.decomposition import TruncatedSVD

#Initialize the flask App
app = Flask(__name__)
model = pickle.load(open('model.pkl', 'rb'))
vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))
le = pickle.load(open('encoder.pkl', 'rb'))
svd = pickle.load(open('svd.pkl', 'rb'))


#default page of our web-app
@app.route('/')
def home():
    return render_template('index.html')

#To use the predict button in our web-app
@app.route('/predict',methods=['POST'])

def predict():
    '''
    For rendering results on HTML GUI
    '''
    int_features = [str(x) for x in request.form.values()]
    print(type(int_features))

    lst_stopwords = nltk.corpus.stopwords.words("english")
    for i in int_features:
      i = utils_preprocess_text(i, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords)

    #for i in int_features:
    int_features = vectorizer.transform(int_features)
    #svd = TruncatedSVD(random_state=42)
    int_features=svd.transform(int_features)
    #final_features = np.array(int_features)
    #final_features = [np.array(int_features)]
    #prediction = model.predict(final_features)
    prediction = model.predict(int_features)

    output = le.inverse_transform(prediction)

    #output = round(prediction[0], 2)

    return render_template('index.html', prediction_text='Deceptive/Truthful: {}'.format(output))

def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):
    ## clean (convert to lowercase and remove punctuations and characters and then strip)
    text = re.sub(r'[^\w\s]', '', str(text).lower().strip())
            
    ## Tokenize (convert from string to list)
    lst_text = text.split()
    ## remove Stopwords
    if lst_stopwords is not None:
        lst_text = [word for word in lst_text if word not in lst_stopwords]
                
    ## Stemming (remove -ing, -ly, ...)
    if flg_stemm == True:
        ps = nltk.stem.porter.PorterStemmer()
        lst_text = [ps.stem(word) for word in lst_text]
                
    ## Lemmatisation (convert the word into root word)
    if flg_lemm == True:
        lem = nltk.stem.wordnet.WordNetLemmatizer()
        lst_text = [lem.lemmatize(word) for word in lst_text]
            
    ## back to string from list
    text = " ".join(lst_text)
    return text



if __name__ == "__main__":
    app.run(debug=True)
